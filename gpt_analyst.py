import logging
from typing import Optional, List, Dict, Any
import json

from openai import AsyncOpenAI

from config import OPENAI_API_KEY, GPT_MODEL, GPT_MAX_TOKENS, GPT_TEMPERATURE, ADX_THRESHOLD, DI_PLUS_THRESHOLD
from models import StockData

logger = logging.getLogger(__name__)


class GPTAnalyst:
    """ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ°ĞºÑ†Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ GPT"""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        self.model = GPT_MODEL
    
    async def analyze_stock(self, stock_data: StockData, candles_data: List[Dict[str, Any]]) -> Optional[str]:
        """
        ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ°ĞºÑ†Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ GPT
        
        Args:
            stock_data: Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ°ĞºÑ†Ğ¸Ğ¸ Ñ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸
            candles_data: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… ÑĞ²ĞµÑ‡ĞµĞ¹
            
        Returns:
            Ğ¢ĞµĞºÑÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¾Ñ‚ GPT Ğ¸Ğ»Ğ¸ None Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ
        """
        try:
            # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ GPT
            prompt = self._create_prompt(stock_data, candles_data)
            
            logger.info(f"ğŸ¤– Ğ—Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµĞ¼ GPT Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ»Ñ {stock_data.info.ticker}...")
            
            # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº GPT
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": self._get_system_prompt()
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_completion_tokens=GPT_MAX_TOKENS
            )
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ¾Ñ‚Ğ²ĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ content
            if not response.choices or not response.choices[0].message.content:
                logger.error(f"âš ï¸ GPT Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ´Ğ»Ñ {stock_data.info.ticker}")
                return None
            
            analysis = response.choices[0].message.content.strip()
            
            logger.info(f"âœ… GPT Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ´Ğ»Ñ {stock_data.info.ticker}")
            logger.info(f"ğŸ“ Ğ”Ğ»Ğ¸Ğ½Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: {len(analysis)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
            logger.info(f"ğŸ“„ Ğ¢ĞµĞºÑÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: {analysis[:200]}...")  # ĞŸĞµÑ€Ğ²Ñ‹Ğµ 200 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
            
            if not analysis:
                logger.warning(f"âš ï¸ GPT Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾ÑĞ»Ğµ strip Ğ´Ğ»Ñ {stock_data.info.ticker}")
                return None
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ Ğº GPT Ğ´Ğ»Ñ {stock_data.info.ticker}: {e}")
            return None
    
    def _get_system_prompt(self) -> str:
        """Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ GPT"""
        return """Ğ¢Ñ‹ Ğ¾Ğ¿Ñ‹Ñ‚Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº Ñ€Ğ¾ÑÑĞ¸Ğ¹ÑĞºĞ¾Ğ³Ğ¾ Ñ„Ğ¾Ğ½Ğ´Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ€Ñ‹Ğ½ĞºĞ° Ñ 15-Ğ»ĞµÑ‚Ğ½Ğ¸Ğ¼ ÑÑ‚Ğ°Ğ¶ĞµĞ¼.

Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° - Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‡Ğ°ÑĞ¾Ğ²Ñ‹Ğµ ÑĞ²ĞµÑ‡Ğ¸ Ğ°ĞºÑ†Ğ¸Ğ¹ Ğ¸ Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğµ, ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸.

Ğ’ĞĞ–ĞĞ:
- ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ĞšĞ ĞĞ¢ĞšĞ Ğ¸ ĞŸĞ Ğ”Ğ•Ğ›Ğ£ (Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 6-8 ÑÑ‚Ñ€Ğ¾Ğº)
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ ÑĞ·Ñ‹Ğº, Ğ¿Ğ¾Ğ½ÑÑ‚Ğ½Ñ‹Ğ¹ Ğ½Ğ¾Ğ²Ğ¸Ñ‡ĞºĞ°Ğ¼
- Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ¹ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ ÑƒÑ€Ğ¾Ğ²Ğ½Ğ¸ Ñ†ĞµĞ½
- Ğ”Ğ°Ğ²Ğ°Ğ¹ Ñ‡ĞµÑ‚ĞºÑƒÑ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ: ĞŸĞĞšĞ£ĞŸĞĞ¢Ğ¬ / Ğ–Ğ”ĞĞ¢Ğ¬ / ĞĞ• Ğ’Ğ¥ĞĞ”Ğ˜Ğ¢Ğ¬
- Ğ•ÑĞ»Ğ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑˆÑŒ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºÑƒ - ÑƒĞºĞ°Ğ¶Ğ¸ Ñ†ĞµĞ»ĞµĞ²ÑƒÑ Ñ†ĞµĞ½Ñƒ Ğ¸ ÑÑ‚Ğ¾Ğ¿-Ğ»Ğ¾ÑÑ

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°:
ğŸ“Š [ĞšÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ² Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ´Ğ°]
ğŸ’¡ [Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ Ñ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼Ğ¸]

ĞĞ• Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ»Ğ¸ÑˆĞ½Ğ¸Ğµ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸, ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸ Ñ„Ğ»Ğ°Ğ³Ğ¾Ğ², Ğ¸ Ğ¸Ğ·Ğ±Ñ‹Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ."""
    
    def _create_prompt(self, stock_data: StockData, candles_data: List[Dict[str, Any]]) -> str:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° Ğ´Ğ»Ñ GPT"""
        
        # Ğ‘ĞµÑ€ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 20 ÑĞ²ĞµÑ‡ĞµĞ¹ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
        recent_candles = candles_data[-20:] if len(candles_data) > 20 else candles_data
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ²ĞµÑ‡Ğ¸
        candles_text = self._format_candles(recent_candles)
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚
        prompt = f"""ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ‡Ğ°ÑĞ¾Ğ²Ñ‹Ğµ ÑĞ²ĞµÑ‡Ğ¸ Ğ°ĞºÑ†Ğ¸Ğ¸ {stock_data.info.ticker} ({stock_data.info.name}):

Ğ¡Ğ’Ğ•Ğ§Ğ˜ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 20):
{candles_text}

Ğ¢Ğ•ĞšĞ£Ğ©Ğ˜Ğ• Ğ˜ĞĞ”Ğ˜ĞšĞĞ¢ĞĞ Ğ«:
â€¢ Ğ¦ĞµĞ½Ğ°: {stock_data.price.current_price:.2f} â‚½
â€¢ EMA20: {stock_data.technical.ema20:.2f} â‚½
â€¢ ADX: {stock_data.technical.adx:.2f} (Ğ¿Ğ¾Ñ€Ğ¾Ğ³ ÑĞ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚Ñ€ĞµĞ½Ğ´Ğ°: {ADX_THRESHOLD})
â€¢ DI+: {stock_data.technical.di_plus:.2f}
â€¢ DI-: {stock_data.technical.di_minus:.2f}

Ğ£Ğ¡Ğ›ĞĞ’Ğ˜Ğ¯ Ğ”Ğ›Ğ¯ ĞŸĞĞšĞ£ĞŸĞšĞ˜ Ğ² Ğ½Ğ°ÑˆĞµĞ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ğµ:
â€¢ ADX > {ADX_THRESHOLD} AND DI+ > {DI_PLUS_THRESHOLD}

Ğ”Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ."""
        
        return prompt
    
    def _format_candles(self, candles: List[Dict[str, Any]]) -> str:
        """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ²ĞµÑ‡ĞµĞ¹ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°"""
        lines = []
        for i, candle in enumerate(candles, 1):
            time = candle['time']
            o = candle['open']
            h = candle['high']
            l = candle['low']
            c = candle['close']
            v = candle['volume']
            
            # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ†Ğ²ĞµÑ‚ ÑĞ²ĞµÑ‡Ğ¸
            color = "ğŸŸ¢" if c > o else "ğŸ”´" if c < o else "âšª"
            
            lines.append(f"{i}. {time} {color} O:{o:.2f} H:{h:.2f} L:{l:.2f} C:{c:.2f} V:{v}")
        
        return "\n".join(lines)


# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€
gpt_analyst = GPTAnalyst()
