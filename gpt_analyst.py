import logging
from typing import Optional, List, Dict, Any
import json

from openai import AsyncOpenAI

from config import OPENAI_API_KEY, GPT_MODEL, GPT_MAX_TOKENS, GPT_TEMPERATURE, ADX_THRESHOLD, DI_PLUS_THRESHOLD
from models import StockData

logger = logging.getLogger(__name__)


class GPTAnalyst:
    """ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ°ĞºÑ†Ğ¸Ğ¹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ GPT"""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        self.model = GPT_MODEL
    
    async def analyze_stock(self, stock_data: StockData, candles_data: List[Dict[str, Any]]) -> Optional[str]:
        """
        ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ°ĞºÑ†Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ GPT
        
        Args:
            stock_data: Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ°ĞºÑ†Ğ¸Ğ¸ Ñ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸
            candles_data: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… ÑĞ²ĞµÑ‡ĞµĞ¹
            
        Returns:
            Ğ¢ĞµĞºÑÑ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¾Ñ‚ GPT Ğ¸Ğ»Ğ¸ None Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ
        """
        try:
            # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ GPT
            prompt = self._create_prompt(stock_data, candles_data)
            
            logger.info(f"ğŸ¤– Ğ—Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµĞ¼ GPT Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ»Ñ {stock_data.info.ticker}...")
            
            # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº GPT
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": self._get_system_prompt()
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_completion_tokens=GPT_MAX_TOKENS,
                reasoning_effort="minimal"  # ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ reasoning Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²
            )
            
            # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸
            logger.info(f"ğŸ” Response structure: {response.model_dump_json()[:500]}")
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ¾Ñ‚Ğ²ĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ content
            if not response.choices or not response.choices[0].message.content:
                logger.error(f"âš ï¸ GPT Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ content Ğ´Ğ»Ñ {stock_data.info.ticker}")
                logger.error(f"Response: {response.model_dump_json()}")
                return None
            
            analysis = response.choices[0].message.content.strip()
            
            logger.info(f"âœ… GPT Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ´Ğ»Ñ {stock_data.info.ticker}")
            logger.info(f"ğŸ“ Ğ”Ğ»Ğ¸Ğ½Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: {len(analysis)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
            logger.info(f"ğŸ“„ Ğ¢ĞµĞºÑÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: {analysis[:200]}...")  # ĞŸĞµÑ€Ğ²Ñ‹Ğµ 200 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
            
            if not analysis:
                logger.warning(f"âš ï¸ GPT Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾ÑĞ»Ğµ strip Ğ´Ğ»Ñ {stock_data.info.ticker}")
                return None
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ Ğº GPT Ğ´Ğ»Ñ {stock_data.info.ticker}: {e}")
            return None
    
    def _get_system_prompt(self) -> str:
        """Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ GPT"""
        return """Ğ¢Ñ‹ Ğ¾Ğ¿Ñ‹Ñ‚Ğ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞ¹Ğ´ĞµÑ€ Ñ€Ğ¾ÑÑĞ¸Ğ¹ÑĞºĞ¾Ğ³Ğ¾ Ñ„Ğ¾Ğ½Ğ´Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ€Ñ‹Ğ½ĞºĞ° Ñ 15-Ğ»ĞµÑ‚Ğ½Ğ¸Ğ¼ ÑÑ‚Ğ°Ğ¶ĞµĞ¼.

Ğ¢Ñ‹ Ñ‡Ğ°ÑÑ‚ÑŒ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ½Ğ° Ğ¿Ğ¾ĞºÑƒĞ¿ĞºÑƒ (long-only), Ğ±ĞµĞ· ÑˆĞ¾Ñ€Ñ‚Ğ¾Ğ².

ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ:
- ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 5-6 ÑÑ‚Ñ€Ğ¾Ğº Ğ’Ğ¡Ğ•Ğ“Ğ
- ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ ÑĞ·Ñ‹Ğº, ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾
- Ğ‘Ğ•Ğ— Ğ´Ğ²Ğ¾ĞµÑ‚Ğ¾Ñ‡Ğ¸Ğ¹ Ğ¿Ğ¾ÑĞ»Ğµ ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸
- ĞĞ´Ğ½Ğ° Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ: ĞŸĞĞšĞ£ĞŸĞĞ¢Ğ¬ / Ğ–Ğ”ĞĞ¢Ğ¬ / ĞĞ• Ğ’Ğ¥ĞĞ”Ğ˜Ğ¢Ğ¬

ĞŸĞ Ğ˜ĞœĞ•Ğ  Ğ˜Ğ”Ğ•ĞĞ›Ğ¬ĞĞĞ“Ğ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:
ğŸ“Š Ğ¦ĞµĞ½Ğ° 115â‚½ Ğ¾ĞºĞ¾Ğ»Ğ¾ EMA20, Ğ±Ğ¾ĞºĞ¾Ğ²Ğ¸Ğº. ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° 114â‚½, ÑĞ¾Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ»ĞµĞ½Ğ¸Ğµ 117â‚½.
ğŸ¤– ĞĞ²Ñ‚Ğ¾ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ° Ğ½ĞµÑ‚ â€” DI+ = 23.20 (Ğ½ÑƒĞ¶Ğ½Ğ¾ >25).
ğŸ’¡ Ğ–Ğ”ĞĞ¢Ğ¬ Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ñ 117â‚½ Ğ¸Ğ»Ğ¸ Ñ€Ğ¾ÑÑ‚Ğ° DI+ Ğ²Ñ‹ÑˆĞµ 25. Ğ¦ĞµĞ»ÑŒ 119â‚½, ÑÑ‚Ğ¾Ğ¿ 114â‚½.

ĞĞ• Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹: "ÑˆĞ¾Ñ€Ñ‚", "Ğ»Ğ¾Ğ½Ğ³", "Ñ‚ĞµĞ¹Ğº", "Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ñ‚", "Ğ±Ğ¾Ñ‚", Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸, Ğ´Ğ²Ğ¾ĞµÑ‚Ğ¾Ñ‡Ğ¸Ñ Ğ¿Ğ¾ÑĞ»Ğµ ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸."""
    
    def _create_prompt(self, stock_data: StockData, candles_data: List[Dict[str, Any]]) -> str:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° Ğ´Ğ»Ñ GPT"""
        
        # Ğ‘ĞµÑ€ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 20 ÑĞ²ĞµÑ‡ĞµĞ¹ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
        recent_candles = candles_data[-20:] if len(candles_data) > 20 else candles_data
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ²ĞµÑ‡Ğ¸
        candles_text = self._format_candles(recent_candles)
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚
        prompt = f"""ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ {stock_data.info.ticker} ({stock_data.info.name}):

Ğ¡Ğ’Ğ•Ğ§Ğ˜ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 20):
{candles_text}

Ğ¢Ğ•ĞšĞ£Ğ©ĞĞ¯ Ğ¡Ğ˜Ğ¢Ğ£ĞĞ¦Ğ˜Ğ¯:
â€¢ Ğ¦ĞµĞ½Ğ°: {stock_data.price.current_price:.2f} â‚½
â€¢ EMA20: {stock_data.technical.ema20:.2f} â‚½
â€¢ ADX: {stock_data.technical.adx:.2f}
â€¢ DI+: {stock_data.technical.di_plus:.2f}
â€¢ DI-: {stock_data.technical.di_minus:.2f}

Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ Ğ‘ĞĞ¢Ğ (Ğ´Ğ»Ñ ÑĞ¿Ñ€Ğ°Ğ²ĞºĞ¸):
Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸: ADX > {ADX_THRESHOLD} AND DI+ > {DI_PLUS_THRESHOLD}
Ğ¡Ğ¸Ğ³Ğ½Ğ°Ğ» Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸: ADX â‰¤ {ADX_THRESHOLD} OR DI+ â‰¤ {DI_PLUS_THRESHOLD}

Ğ”Ğ°Ğ¹ ÑĞ²Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·."""
        
        return prompt
    
    def _format_candles(self, candles: List[Dict[str, Any]]) -> str:
        """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ²ĞµÑ‡ĞµĞ¹ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°"""
        lines = []
        for i, candle in enumerate(candles, 1):
            time = candle['time']
            o = candle['open']
            h = candle['high']
            l = candle['low']
            c = candle['close']
            v = candle['volume']
            
            # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ†Ğ²ĞµÑ‚ ÑĞ²ĞµÑ‡Ğ¸
            color = "ğŸŸ¢" if c > o else "ğŸ”´" if c < o else "âšª"
            
            lines.append(f"{i}. {time} {color} O:{o:.2f} H:{h:.2f} L:{l:.2f} C:{c:.2f} V:{v}")
        
        return "\n".join(lines)


# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€
gpt_analyst = GPTAnalyst()
